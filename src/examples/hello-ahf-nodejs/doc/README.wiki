= NodeJS example =

== Previous steps ==

Before starting up this container, ensure that you have the necessary core services up and running. If you are running this from the Arrowhead repository, it should be as simple as running the following command. You can manually substitute the <code>AHF_DOCKER_PATH</code> environment variable if you have not set it up previously.

'''Linux'''

<pre>$ docker-compose up --build ${AHF_DOCKER_PATH}/core</pre>
'''Windows'''

<pre>&gt; docker-compose up --build %AHF_DOCKER_PATH%\core</pre>
== How to use ==

'''Linux'''

<pre>$ docker build -t hello-ahf-java-pure .
$ docker run --rm \
           --name hello-ahf-java-pure \
           --hostname hello.docker.ahf \
           --net-alias hello.docker.ahf \
           -p 8888:8888 \
           --volume tls:/tls \
           --network ahf \
           hello-ahf-java-pure</pre>
'''Windows'''

<pre>&gt; docker build -t hello-ahf-java-pure .
&gt; docker run --rm ^
           --name hello-ahf-java-pure ^
           --hostname hello.docker.ahf ^
           --net-alias hello.docker.ahf ^
           -p 8888:8888 ^
           --volume core_tls:/tls ^
           --network core_ahf ^
           hello-ahf-java-pure</pre>
Please note that the network and volume parameters might be different depending on your environment. The given values should work if you started the the core containers using docker-compose in the same machine.

If you are planning on connecting to core services on a remote host, you will need to use a mount volume (i.e. create a Docker volume which allows a directory on your host to be accessed by containers) and provide the corresponding addresses for accessing the remote host.

== Setup before testing ==

Before performing the tests below, you need a certificate signed by the core/glassfish container's CA. This is automatically done by this container. Ideally, you should also use the CA to validate the container's response. This is is also provided.

To retrieve these files, run

<pre>docker cp hello-ahf-java-pure:/client/ .</pre>
This will copy the <code>client/</code> directory from the container into your current location. This directory contains the files you need.

<pre>cd client
ls</pre>
You should also have curl installed or any other similar application for performing web requests.

Finally, your system needs to recognize the hello.docker.ahf host. You can achieve this in multiple ways. The easiest being to modify your hosts file to include the following line (or the corresponding depending on where you are running the container).

<pre>127.0.0.1 hello.docker.ahf</pre>
== Test calls ==

=== Setup ===

This endpoint allows the service to register itself on the Service and Authorisation Registries. This is for easy demonstration purposes, security must be considered in real applications.

Currently, the authorisation rule is to allow any caller whose certified name is <code>client.docker.ahf</code> (which is the case for the certificate obtained above).

<pre>curl -X POST --cert client.pem:changeit --cacert ca.crt https://hello.docker.ahf:8888/setup</pre>
=== Setdown ===

This endpoint allows the service to un-register itself from the Service and Authorisation Registries. This is for easy demonstration purposes, security must be considered in real applications.

<pre>curl -X POST --cert client.pem:changeit --cacert ca.crt https://hello.docker.ahf:8888/setdown</pre>
=== Hello ===

This is an endpoint set to check the identity of the caller and check for authorisation in the Authorisation Registry. If the caller is authorised, the response will be &quot;Hello&quot;, otherwise, the response will inform the caller that they are not authorised.

<pre>curl -X POST --cert client.pem:changeit --cacert ca.crt https://hello.docker.ahf:8888/hello</pre>
Recommended tests are:

* Run before doing setup (or after doing setdown).
* Run after doing setup.
* Run without providing a certificate (removing the <code>--cert</code> parameter).

== Other usage scenarios ==

=== Resin with bootstrapping ===

[Optional] Ensure that the core containers are already running.

<pre>docker-compose up -f ../../core</pre>
[Optional] Ensure that the core containers are bootstrap-publishing.

<pre>SERVER_ADDRESS=$(docker inspect -f &quot;{{ .NetworkSettings.Networks.core_ahf.IPAddress }}&quot; core_bind_1)
[ -n &quot;SERVER_ADDRESS&quot; ] &amp;&amp; \
docker run \
       --rm \
       --network core_ahf \
       --ip 192.168.10.121 \
       --env URI_SCHEME=&quot;dns&quot; \
       --env URI_HOST=&quot;${SERVER_ADDRESS}&quot; \
       --env IP_ADDRESS=&quot;${SERVER_ADDRESS}&quot; \
       --env MCAST_INTERFACE=&quot;192.168.10.121&quot; \
       --name socat-bootstrap-server \
       socat-bootstrap-server</pre>
[Optional] Remove the Docker network.

<pre>docker -H tcp://resin1.local:2375 network rm mcast_net</pre>
[Optional] Recreate it.

<pre>docker -H tcp://resin1.local:2375 network create \
             -d macvlan \
             --subnet=192.168.10.0/24 \
             --gateway=192.168.10.180 \
             -o parent=eth0 \
             mcast_net</pre>
[Optional] Create and fill the tls volume (assumes core is running locally)

<pre>docker -H tcp://resin1.local:2375 volume create tls 
docker -H tcp://resin1.local:2375 run --rm --name temp --volume tls:/tls -dit alpine
docker cp core_glassfish_1:/tls/ .
cd tls
keytool -import \
    -trustcacerts \
    -alias &quot;ca&quot; \
    -file &quot;ca.crt&quot; \
    -keystore &quot;ca.jks&quot; \
    -storepass &quot;changeit&quot; \
    -noprompt
sed -i '$ d' generate-signed-cert.sh
./generate-signed-cert.sh hello-ahf hello.docker.ahf changeit
./generate-signed-cert.sh client client.docker.ahf changeit
mkdir -p ../client
mv client* ca.crt ../client
docker -H tcp://resin1.local:2375 cp . temp:/tls/
cd ..
docker -H tcp://resin1.local:2375 stop temp
rm -rf tls</pre>
(Another idea when running all locally -- should build tool container... this requires downloading something extra)

<pre>docker volume create tls
docker volume create tsig
docker run \
       --rm \
       -it \
       --volume core_tls:/core_tls \
       --volume core_tsig:/core_tsig \
       --volume tls:/tls \
       --volume tsig:/tsig \
       openjdk:8-jdk-alpine
apk --no-cache add openssl
cd /core_tls
keytool -import \
    -trustcacerts \
    -alias &quot;ca&quot; \
    -file &quot;ca.crt&quot; \
    -keystore &quot;ca.jks&quot; \
    -storepass &quot;changeit&quot; \
    -noprompt
./generate-signed-cert.sh hello-ahf hello.docker.ahf changeit
./generate-signed-cert.sh client client.docker.ahf changeit
cp -f ./* /tls
cp -f /core_tsig/tsig /tsig
exit;</pre>
Build the images.

<pre>docker -H tcp://resin1.local:2375 build \
            --tag socat-bootstrap-client \
            ../../discovery-bootstrapping/multicast/plain/socat/client
docker -H tcp://resin1.local:2375 build \
            --tag hello-ahf-nodejs .</pre>
Run the containers.

<pre>docker -H tcp://resin1.local:2375 run \
           --rm \
           --network mcast_net \
           --ip 192.168.10.181 \
           --name socat-bootstrap-client \
           --env OUTPUT_FILENAME=&quot;bootstrap&quot; \
           --volume bootstrapping:/out \
           socat-bootstrap-client
docker -H tcp://resin1.local:2375 run \
           --rm \
           --network mcast_net \
           --ip 192.168.10.182 \
           --name hello-ahf-nodejs \
           --hostname hello.docker.ahf \
           -p 3111:3111 \
           --volume tls:/tls \
           --volume bootstrapping:/boots \
           --env BOOTSTRAPPING_PATH=&quot;/boots/bootstrap&quot; \
           hello-ahf-nodejs</pre>
Set the hosts file for the current location of the container

<pre>sudo sed -Ei &quot;s/^[1-9].*hello\.docker\.ahf/127.0.0.1 hello.docker.ahf/g&quot; /etc/hosts</pre>
Test

<pre>curl -X GET --cert client/client.pem:changeit --cacert client/ca.crt https://hello.docker.ahf:3111/setup
curl -X GET --cert client/client.pem:changeit --cacert client/ca.crt https://hello.docker.ahf:3111/hello
curl -X GET --cert client/client.pem:changeit --cacert client/ca.crt https://hello.docker.ahf:3111/setdown
curl -X GET --cert client/client.pem:changeit --cacert client/ca.crt https://hello.docker.ahf:3111/hello</pre>
Clean up

<pre>rm -rf client</pre>
== Environment variables ==

By setting any of the following environment variables when running the container, you can use it in more complex contexts. For example, you could connect to core services on a remote host, or use a different certificate, obtained from a volume mounted on your host.

=== KEYSTORE_LOCATION ===

Default: <code>hello.jks</code>

=== CACERTS_LOCATION ===

Default: <code>ca.jks</code>

=== KEYSTORE_PASSPHRASE ===

Default: <code>changeit</code>

=== SERVICE_DISCOVERY_URL ===

Default: <code>http://simpleservicediscovery.docker.ahf:8045/servicediscovery</code>

=== ORCHESTRATION_URL ===

Default: <code>https://glassfish.docker.ahf:8181/orchestration/store</code>

=== AUTHORISATION_URL ===

Default: <code>http://glassfish.docker.ahf:8080/authorisation</code>

=== AUTHORISATION_CONTROL_URL ===

Default: <code>https://glassfish.docker.ahf:8181/authorisation-control</code>

=== AUTHORIZED_CN ===

Default: <code>client.docker.ahf</code>

=== PORT ===

Default: <code>8888</code>

=== BOOTSTRAPPING_PATH ===

No default.

=== Virtualbox demo execute from ahf-docker/ ===

Missing: * Hello must register itself with DNS

Preparation: * Might need to open ports inside the NAT? I assume they are just not closed in the local network. * Create TLS and TSIG in VM 1 * Copy them to VM 2 and VM 3

Steps: VM 1: * Run the core containers detached * Run DNS bootstrapper detached same VM

VM 2: * Run bootstrapper leading to volume * Run hello-nodejs connected to bootstrapping, TLS and TSIG volumes with the necessary port open

VM 3: * Run test calls to hello-nodejs

<ul>
<li><p>Start the VMs</p>
<pre>VBoxManage startvm ud1 --type headless
VBoxManage startvm ud2 --type headless
VBoxManage startvm ud3 --type headless
ssh r@10.0.0.1 -p22222
ssh r@10.0.0.2 -p22222
ssh r@10.0.0.3 -p22222</pre></li>
<li><p>Create TLS and TSIG in VM 1</p>
<pre>docker-compose -f core/docker-compose.yml run glassfish tls</pre></li>
<li><p>Copy them to removable media ```bash mkdir -p .media/tls .media/tsig sudo cp -far &quot;$(docker volume inspect core_tls -f '{{ .Mountpoint }}')/.&quot; .media/tls/ &amp;&amp; sudo chown -R *U'''S'''E**R*:{USER} .media/tls</p></li></ul>

cd .media/tls keytool -import<br />
-trustcacerts<br />
-alias &quot;ca&quot;<br />
-file &quot;ca.crt&quot;<br />
-keystore &quot;ca.jks&quot;<br />
-storepass &quot;changeit&quot;<br />
-noprompt ./generate-signed-cert.sh hello-ahf hello.docker.ahf changeit ./generate-signed-cert.sh client client.docker.ahf changeit cd - sudo cp -far &quot;$(docker volume inspect core_tsig -f '{{ .Mountpoint }}')/.&quot; .media/tsig/ &amp;&amp; sudo chown -R *U'''S'''E**R*:{USER} .media/tls device_path=/dev/sda1 sudo umount .media sudo mount &quot;${device_path}&quot; .media &amp;&amp;<br />
cp -far tls tsig .media/ sudo umount .media rm -rf .media ```

<ul>
<li><p>Copy them to VM 2 and VM 3 On VM 1</p>
<pre>mkdir -p ~/tls ~/tsig;
sudo cp -far &quot;$(docker volume inspect core_tls -f '{{ .Mountpoint }}')/.&quot; ~/tls/ &amp;&amp; sudo chown -R ${USER}:${USER} ~/tls; 
sudo cp -far &quot;$(docker volume inspect core_tsig -f '{{ .Mountpoint }}')/.&quot; ~/tsig/ &amp;&amp; sudo chown -R ${USER}:${USER} ~/tsig;</pre></li></ul>

On the host

<pre># TODO: Check contents
scp -P 22222 -r r@10.0.0.1:~/tls/ tls
scp -P 22222 -r r@10.0.0.1:~/tsig/ tsig
cd tls
keytool -import \
    -trustcacerts \
    -alias &quot;ca&quot; \
    -file &quot;ca.crt&quot; \
    -keystore &quot;ca.jks&quot; \
    -storepass &quot;changeit&quot; \
    -noprompt
./generate-signed-cert.sh hello-ahf hello.docker.ahf changeit
./generate-signed-cert.sh client client.docker.ahf changeit
cd -
scp -P 22222 -r tls/ tsig/ r@10.0.0.2:~/
scp -P 22222 -r tls/ tsig/ r@10.0.0.3:~/
rm -rf tls/ tsig/</pre>
[Optional] Ensure that the core containers are already running.

<pre>docker-compose -f ~/ahf-docker/core/docker-compose.yml up -d</pre>
[Optional] Ensure that the core containers are bootstrap-publishing.

<pre>docker build \
       --tag socat-bootstrap-server \
       ~/ahf-docker/discovery-bootstrapping/multicast/plain/socat/core/
docker run \
       --restart always \
       --detach \
       --network host \
       --env URI_SCHEME=&quot;dns&quot; \
       --env PUBLISH_INTERFACE_NAME=&quot;enp0s3&quot; \
       --env MCAST_INTERFACE_NAME=&quot;enp0s3&quot; \
       --name socat-bootstrap-server \
       socat-bootstrap-server</pre>
[Optional] Remove the Docker network.

<pre>docker network rm mcast_net</pre>
[Optional] Recreate it.

<pre>docker network create \
             -d macvlan \
             --subnet=192.168.10.0/24 \
             --gateway=192.168.10.180 \
             -o parent=eth0 \
             mcast_net</pre>
[Optional] Create and fill the tls and tsig volumes (VM2)

<pre>docker volume create tls
docker volume create tsig
docker run --rm --name temp --volume tls:/tls --volume tsig:/tsig -dit alpine
docker cp ~/tls/. temp:/tls/
docker cp ~/tsig/. temp:/tsig/
docker stop temp
rm -rf tls</pre>
Build the images.

<pre>scp -P 22222 -r ~/ws/ahf-docker/ r@10.0.0.2:~/

docker build \
            --tag socat-bootstrap-client \
            ~/ahf-docker/discovery-bootstrapping/multicast/plain/socat/client
docker stop hello-ahf-nodejs
docker rm hello-ahf-nodejs
docker build \
            --tag hello-ahf-nodejs \
            ~/ahf-docker/examples/hello-ahf-nodejs</pre>
Run the containers.

<pre>docker volume create bootstrapping
docker run \
           --rm \
           --network host \
           --name socat-bootstrap-client \
           --env OUTPUT_FILENAME=&quot;bootstrap&quot; \
           --volume bootstrapping:/out \
           socat-bootstrap-client
docker run \
           --rm \
           --network host \
           --name hello-ahf-nodejs \
           --hostname hello.docker.ahf \
           -p 3111:3111 \
           --volume tls:/tls \
           --volume tsig:/tsig \
           --volume bootstrapping:/boots \
           --env REGISTER_WITH_DNS=true \
           --env BOOTSTRAPPING_PATH=&quot;/boots/bootstrap&quot; \
           hello-ahf-nodejs</pre>
Alternatively, run the containers detached and to restart always.

<pre>docker volume create bootstrapping
docker run \
           --restart always \
           --detach \
           --network host \
           --name socat-bootstrap-client \
           --env OUTPUT_FILENAME=&quot;bootstrap&quot; \
           --volume bootstrapping:/out \
           socat-bootstrap-client
docker run \
           --restart always \
           --detach \
           --network host \
           --name hello-ahf-nodejs \
           --hostname hello.docker.ahf \
           -p 3111:3111 \
           --volume tls:/tls \
           --volume tsig:/tsig \
           --volume bootstrapping:/boots \
           --env REGISTER_WITH_DNS=true \
           --env BOOTSTRAPPING_PATH=&quot;/boots/bootstrap&quot; \
           --env IP_INTERFACE_NAME=&quot;enp0s3&quot; \
           --env DO_DYNAMIC_DNS_UPDATE=true \
           hello-ahf-nodejs</pre>
Get the DNS server on the client

<pre>docker run \
           --rm \
           --network host \
           --name socat-bootstrap-client \
           --env OUTPUT_FILENAME=&quot;bootstrap&quot; \
           --volume bootstrapping:/out \
           socat-bootstrap-client | sed -E 's/.* (.*)/nameserver \1/g' &gt; resolv.conf
sudo cp -f {.,/etc}/resolv.conf
ping glassfish.docker.ahf
ping hello.docker.ahf</pre>
Test

<pre>curl -X GET --cert ~/tls/client.pem:changeit --cacert ~/tls/ca.crt https://hello.docker.ahf:3111/setup
curl -X GET --cert ~/tls/client.pem:changeit --cacert ~/tls/ca.crt https://hello.docker.ahf:3111/hello
curl -X GET --cert ~/tls/client.pem:changeit --cacert ~/tls/ca.crt https://hello.docker.ahf:3111/setdown
curl -X GET --cert ~/tls/client.pem:changeit --cacert ~/tls/ca.crt https://hello.docker.ahf:3111/hello</pre>
Change net

<pre>VBoxManage controlvm &quot;ud1&quot; nic1 natnetwork net192 &amp;&amp; \
VBoxManage controlvm &quot;ud2&quot; nic1 natnetwork net192 &amp;&amp; \
VBoxManage controlvm &quot;ud3&quot; nic1 natnetwork net192

sudo systemctl restart networking.service</pre>
Clean up Host

<pre>VBoxManage controlvm &quot;ud1&quot; nic1 natnetwork net10 &amp;&amp; \
VBoxManage controlvm &quot;ud2&quot; nic1 natnetwork net10 &amp;&amp; \
VBoxManage controlvm &quot;ud3&quot; nic1 natnetwork net10
VBoxManage controlvm &quot;ud1&quot; acpipowerbutton
VBoxManage controlvm &quot;ud2&quot; acpipowerbutton
VBoxManage controlvm &quot;ud3&quot; acpipowerbutton</pre>
All VMS

<pre>sudo systemctl restart networking.service</pre>
<ul>
<li><p>Start the VMs</p>
<pre>VBoxManage startvm ud1 --type headless
VBoxManage startvm ud2 --type headless
VBoxManage startvm ud3 --type headless
ssh r@10.0.0.1 -p22222
ssh r@10.0.0.2 -p22222
ssh r@10.0.0.3 -p22222</pre></li></ul>

VM 3

<pre>sudo cp -f /etc/resolv.conf{.bkp,}
rm -rf client</pre>
Extra

<pre>vm=ud3 &amp;&amp; VBoxManage controlvm &quot;$vm&quot; nic1 natnetwork net192 &amp;&amp; VBoxManage controlvm $vm setlinkstate1 off &amp;&amp; VBoxManage controlvm $vm setlinkstate1 on

VBoxManage controlvm ud1 setlinkstate1 off
VBoxManage controlvm ud2 setlinkstate1 off
VBoxManage controlvm ud3 setlinkstate1 off
VBoxManage controlvm ud1 setlinkstate1 on
VBoxManage controlvm ud2 setlinkstate1 on
VBoxManage controlvm ud3 setlinkstate1 on</pre>
